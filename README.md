# MLxE Architecture for Reinforcement Learning with Algorithmc Enchancements

# Objectives of the Project:
1.) Introduce the MLxE Architecture, a highly efficient, Multiprocessing based implementation of Reinforcement Learning (RL) algorithms that maximizes the utilization of available hardware recourses. It achieves >2x efficiency improvement relative to Threading based implementations in the test environment.

2.) Propose addition of the "Task-at-Hand" specific modifications to the learning process to maximize the learining efficiency

3.) Update the classical implemntations of A3C, RAINBOW and SEC algorithms with recent developments in the field of RL

# MLxE Architecture
MLxE Architecture is designed for RL learning and research applications with focus on ease of understanding and of modifying underlying RL algorithms (A3C, Rainbow, SAC,...) thus it is implemented in linear fashion with limited use of python programmatical overhead (Classes, Functions,...). 

It is implemented in TensorFlow 2 making it one of the most up to date implementations of the RL Algorithms

At its core, MLxE Architecture consist of multiple processes executed in parallel, each with its deditacted function:

M Process - the Memorizer: Manages the Memory of the Learining Agent. It collects examples generated by Executors, modifies them and repackages them for consumption by the Learner

L Process - the Learner: The core proccess of the Learing Agent responsible for updating model weights through a SGD based algorithm. It consumes the trainig examples prepared by Memorizer and sends updated models to Executors for generation of the next wave of the examples.

xE Processes - the Executors: Generate new examples for trainig utilizing the model computed by the Learner. There are as many executors (x) as there are cores on the machine you are using minus two (those assigned for the Memorizer and the Learner) thus "xE" in the name of the archtecture. For example, this project was created using the ML6E architecture since my machine has 8 CPU cores. You can execute the Learner's calcualtions on GPU but still one CPU core will be dedicated to the process handing the Learner. 

There are three sub-architectures tested. We are comparing their performce and make recomendation for the best performing one: the Iterative-Synchronous MLxE:

1.) Iterative-Synchronious Threading Based (IS TB) - it is our banchark implementation based on modification of a code availabel online.
- Iterative - learning is perfomed intermittently with the example generation
- Synchronious - each executor generates only one example per iteration, waiting idle for closing of all executors and update of the model in given iteration
- Model Updarte for the Learner and Executors is performed in each iteration

2.) Iterative-Synchronious MLxE Based (IS MLxE) - the best performing architecture, used in final implementations of the RL Algorithms
- due to iterative nature of the architecture there are all cores are used as Executors in Example Generation Phase and one process for Memorizing and Learing Phases 

3.) Iterative-Asynchronious MLxE Based (IA MLxE) - During Example Generation Phase all Executors generate examples till each Executor generates at least one Example. Executors respawn if they finish before all Executors generate their first example.

4.) On-Line-Asynchronious MLxE Based (OA MLxE) - the Memorizing and Learing Phases are spawned in their own processes and are run in parallel to the Executors. The model is continously updated as iis new verion becomes avaialble form the Learner and Executors pick them up upon initiallizing the next Example Generation

# "Task-at-Hand" Specific Modifications
